{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0dae6f-de67-4998-8686-24a4d0269572",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Comp-Act dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d957c22-2da8-4668-89c7-b4715a4954eb",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd38e73-cf68-430a-b62a-43cd8f52b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ignite.utils import manual_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c213065-7a90-4b1a-9dc7-dba0b7668c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"../data/compact/compact/ComputerActivity/cpu_act.data\",\n",
    "              delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d357c59-7cb7-4f96-9469-d1ffe5f2efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = np.loadtxt(\"../data/compact/compact/ComputerActivity/cpu_act.domain\", \n",
    "                   dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb72687f-932b-4281-b34b-32147989b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = domain[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57934c66-3956-4f9a-bad6-85fb350054c9",
   "metadata": {},
   "source": [
    "Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd0fd84-80b2-4ebe-ad77-58f3f8b63949",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed(0)\n",
    "shuffled_indices = np.random.permutation(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4912dea9-64ea-4850-aa5f-50d9b835f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ca = data[shuffled_indices, 0:21].astype(np.float32)\n",
    "y_ca = data[shuffled_indices, 21].reshape(-1, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c4b3ac-9937-4deb-b17b-0ae316c39a57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e73e76-3d86-4998-a6e7-28ff68b5c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration.pytorch_ignite import PyTorchIgnitePruningHandler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, RootMeanSquaredError\n",
    "from ignite.handlers import EarlyStopping, LRScheduler, BasicTimeProfiler\n",
    "from pyselect.networks import RandomFourierFeaturesNet\n",
    "from pyselect.data import train_val_test_split\n",
    "from pyselect.train import ridge_loss, score_function, best_model_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9230d34-bd05-47c4-9947-d14b3b68efb0",
   "metadata": {},
   "source": [
    "Set train, validation and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c0ed87-d83e-4b59-ba2d-3e6aa3e0c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 6000\n",
    "test_size = 1000\n",
    "val_size = 1192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742991a-dd2b-402b-bd9f-b9693f95cc07",
   "metadata": {},
   "source": [
    "Data-splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0867597c-a70d-44b9-b6c9-6f7d47fb73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X_ca, y_ca, train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd87216-6e09-4fec-bebd-0fd500f5a762",
   "metadata": {},
   "source": [
    "Change scales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0ab7b-29f3-4566-9b3c-ba58ee65bf4b",
   "metadata": {},
   "source": [
    "For X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0c921c-0ce0-4e72-b782-45e74c6ee206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8763fc-be76-4d16-bda8-6b622298bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78ecef-46ab-4540-bb13-bc0292e75e9c",
   "metadata": {},
   "source": [
    "For y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7179d2-c49e-4bae-9ad3-eb5c08630e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d27ea0-4a17-4f82-a7b2-fbe9d62fb46b",
   "metadata": {},
   "source": [
    "Apply scale changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d198db07-5695-4002-aff8-618e39c19079",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train -= y_train_mean\n",
    "y_val -= y_train_mean\n",
    "y_test -= y_train_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e5fe1-9b42-4e0d-aafd-7c3e836c2feb",
   "metadata": {},
   "source": [
    "Convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c761b402-01a0-40a6-9d71-9b18e2c9ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf6e4389-826a-4451-b16e-dabb9a4f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8a069-d9cf-444f-8987-523f6d54211d",
   "metadata": {},
   "source": [
    "Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6eb8a6-411b-45ea-be69-4c7137ee6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)\n",
    "test_loader = DataLoader(test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3395d6-6859-4d89-8519-13b6ede66f29",
   "metadata": {},
   "source": [
    "Objective for optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3ba6d0-0c1d-4dc5-af5a-b8dd03b43e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # Set optimization seed\n",
    "    seed = trial.number\n",
    "    manual_seed(seed)\n",
    "    trial.set_user_attr('random_seed', value=seed)    \n",
    "    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    trial.set_user_attr('device', value=device)\n",
    "    \n",
    "    in_features = 21\n",
    "    out_features = 600\n",
    "    model = RandomFourierFeaturesNet(in_features, out_features, torch.randn) \n",
    "    model.to(device) \n",
    "\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-3)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    reg_param = trial.suggest_float(\"reg_param\", 1e-7, 1e-5, log=True)\n",
    "    loss_fn = lambda y_pred, y_true: ridge_loss(y_pred, y_true, model, reg_param)\n",
    "    \n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "    \n",
    "    # Add learning rate scheduler\n",
    "    step_size = len(train_loader)*n_epochs//1.7\n",
    "    torch_scheduler = StepLR(optimizer, step_size=step_size, gamma=0.5)\n",
    "    scheduler = LRScheduler(torch_scheduler)\n",
    "    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
    "        \n",
    "    # Add evaluators\n",
    "    val_metric = {\"loss\": Loss(loss_fn)}    \n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metric, device=device)                                                \n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metric, device=device)\n",
    "    \n",
    "    # Add pruner\n",
    "    pruner = PyTorchIgnitePruningHandler(trial, 'loss', trainer)\n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, pruner)\n",
    "\n",
    "    # Loggers\n",
    "    log_every = 100\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=log_every))\n",
    "    def log_training_results(engine):\n",
    "        train_evaluator.run(train_loader)\n",
    "        loss = train_evaluator.state.metrics['loss']\n",
    "        print(f\"Training - Epoch: {engine.state.epoch} Loss: {loss:.5f}\")\n",
    "        \n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=log_every))\n",
    "    def log_validation_results(engine):\n",
    "        val_evaluator.run(val_loader)\n",
    "        loss = val_evaluator.state.metrics['loss']\n",
    "        print(f\"Validation - Epoch: {engine.state.epoch} Loss: {loss:.5f}\")    \n",
    "        \n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=log_every))\n",
    "    def log_lr():\n",
    "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "        \n",
    "    # Attach basic time profiler\n",
    "    time_profiler = BasicTimeProfiler()\n",
    "    time_profiler.attach(trainer)\n",
    "    \n",
    "    # Add early stopping \n",
    "    handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, handler) \n",
    "    \n",
    "    # Train the model\n",
    "    trainer.run(train_loader, max_epochs=n_epochs)\n",
    "    \n",
    "    # Save best model in study parameters\n",
    "    trial.set_user_attr(key='best_model', value=model)    \n",
    "    \n",
    "    # Time evaluation\n",
    "    profiling_results = time_profiler.get_results()\n",
    "    trial.set_user_attr(key='time_profiling', value=profiling_results)\n",
    "    \n",
    "    # Final evaluation\n",
    "    val_evaluator.run(val_loader)\n",
    "    val_loss = val_evaluator.state.metrics['loss']\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3de5f6-27bc-412a-b3e4-53360f05c47f",
   "metadata": {},
   "source": [
    "Initialize optuna study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "745b3395-4787-4a7e-920c-9dba7be5f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_sampler = TPESampler(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d08c1be8-a843-4067-90fa-eb0517992340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 14:48:36,988]\u001b[0m A new study created in memory with name: no-name-b2f57625-26b2-4d0c-b211-b176e3c02401\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize', sampler=tpe_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922f468-b2c7-4560-ba08-ca2eab4b591a",
   "metadata": {},
   "source": [
    "Run study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb63b3bc-5f2e-4166-a360-041feaa944cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10111d04-92a2-48d8-a53f-f5189d71cbf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 68.06269\n",
      "Validation - Epoch: 100 Loss: 74.09842\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 200 Loss: 27.98970\n",
      "Validation - Epoch: 200 Loss: 30.80024\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 300 Loss: 18.97153\n",
      "Validation - Epoch: 300 Loss: 22.01218\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 400 Loss: 15.44098\n",
      "Validation - Epoch: 400 Loss: 16.79368\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 500 Loss: 13.71643\n",
      "Validation - Epoch: 500 Loss: 14.67400\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 600 Loss: 12.70331\n",
      "Validation - Epoch: 600 Loss: 13.54263\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 700 Loss: 11.97044\n",
      "Validation - Epoch: 700 Loss: 12.78139\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 800 Loss: 11.51390\n",
      "Validation - Epoch: 800 Loss: 12.56903\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 900 Loss: 11.43005\n",
      "Validation - Epoch: 900 Loss: 13.45704\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1000 Loss: 10.77618\n",
      "Validation - Epoch: 1000 Loss: 11.58179\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1100 Loss: 10.72485\n",
      "Validation - Epoch: 1100 Loss: 12.01327\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1200 Loss: 11.06963\n",
      "Validation - Epoch: 1200 Loss: 14.17028\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1300 Loss: 10.52359\n",
      "Validation - Epoch: 1300 Loss: 11.92384\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1400 Loss: 10.63221\n",
      "Validation - Epoch: 1400 Loss: 12.50779\n",
      "Learning rate: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 14:53:38,005 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
      "/home/mpotto/.cache/pypoetry/virtualenvs/pyselect-ESLNoovx-py3.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 1500 is already reported.\n",
      "  warnings.warn(\n",
      "2022-02-23 14:53:38,039 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
      "\u001b[32m[I 2022-02-23 14:53:38,042]\u001b[0m Trial 0 finished with value: 12.450370634962248 and parameters: {'learning_rate': 0.0005939321535345923, 'reg_param': 2.6938830192854074e-06}. Best is trial 0 with value: 12.450370634962248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1500 Loss: 10.61613\n",
      "Validation - Epoch: 1500 Loss: 12.45037\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 100 Loss: 70.27423\n",
      "Validation - Epoch: 100 Loss: 80.81505\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 200 Loss: 31.77233\n",
      "Validation - Epoch: 200 Loss: 37.20630\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 300 Loss: 22.06094\n",
      "Validation - Epoch: 300 Loss: 24.53993\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 400 Loss: 18.36422\n",
      "Validation - Epoch: 400 Loss: 19.57923\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 500 Loss: 16.65698\n",
      "Validation - Epoch: 500 Loss: 18.13889\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 600 Loss: 15.52271\n",
      "Validation - Epoch: 600 Loss: 16.48491\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 700 Loss: 14.74735\n",
      "Validation - Epoch: 700 Loss: 17.10630\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 800 Loss: 13.51846\n",
      "Validation - Epoch: 800 Loss: 14.04321\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 900 Loss: 12.79695\n",
      "Validation - Epoch: 900 Loss: 13.26214\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1000 Loss: 12.22137\n",
      "Validation - Epoch: 1000 Loss: 12.65705\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1100 Loss: 11.77745\n",
      "Validation - Epoch: 1100 Loss: 12.20396\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1200 Loss: 11.44522\n",
      "Validation - Epoch: 1200 Loss: 11.88319\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1300 Loss: 11.18871\n",
      "Validation - Epoch: 1300 Loss: 11.64390\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1400 Loss: 10.97233\n",
      "Validation - Epoch: 1400 Loss: 11.45490\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1500 Loss: 10.84395\n",
      "Validation - Epoch: 1500 Loss: 11.34472\n",
      "Learning rate: 0.0006\n",
      "Training - Epoch: 1600 Loss: 10.01077\n",
      "Validation - Epoch: 1600 Loss: 10.54087\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 1700 Loss: 9.94461\n",
      "Validation - Epoch: 1700 Loss: 10.50011\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 1800 Loss: 9.88290\n",
      "Validation - Epoch: 1800 Loss: 10.43891\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 1900 Loss: 9.82423\n",
      "Validation - Epoch: 1900 Loss: 10.38055\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2000 Loss: 9.77569\n",
      "Validation - Epoch: 2000 Loss: 10.31662\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2100 Loss: 9.72476\n",
      "Validation - Epoch: 2100 Loss: 10.26933\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2200 Loss: 9.67662\n",
      "Validation - Epoch: 2200 Loss: 10.22588\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2300 Loss: 9.63048\n",
      "Validation - Epoch: 2300 Loss: 10.18446\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2400 Loss: 9.60118\n",
      "Validation - Epoch: 2400 Loss: 10.19955\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2500 Loss: 9.56128\n",
      "Validation - Epoch: 2500 Loss: 10.17065\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2600 Loss: 9.51739\n",
      "Validation - Epoch: 2600 Loss: 10.12741\n",
      "Learning rate: 0.0003\n",
      "Training - Epoch: 2700 Loss: 9.48030\n",
      "Validation - Epoch: 2700 Loss: 10.09716\n",
      "Learning rate: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 15:02:35,647]\u001b[0m Trial 1 finished with value: 10.09091780489723 and parameters: {'learning_rate': 0.0006424870384644795, 'reg_param': 1.2296071107325702e-06}. Best is trial 1 with value: 10.09091780489723.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 97.38358\n",
      "Validation - Epoch: 100 Loss: 105.99021\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 200 Loss: 44.28432\n",
      "Validation - Epoch: 200 Loss: 47.03916\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 300 Loss: 27.20693\n",
      "Validation - Epoch: 300 Loss: 29.06065\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 400 Loss: 20.61362\n",
      "Validation - Epoch: 400 Loss: 22.36166\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 500 Loss: 17.53293\n",
      "Validation - Epoch: 500 Loss: 19.40813\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 600 Loss: 15.70042\n",
      "Validation - Epoch: 600 Loss: 17.42820\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 700 Loss: 14.40654\n",
      "Validation - Epoch: 700 Loss: 16.06949\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 800 Loss: 13.64654\n",
      "Validation - Epoch: 800 Loss: 15.96501\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 900 Loss: 13.16674\n",
      "Validation - Epoch: 900 Loss: 16.52235\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1000 Loss: 12.33590\n",
      "Validation - Epoch: 1000 Loss: 14.58610\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1100 Loss: 11.81851\n",
      "Validation - Epoch: 1100 Loss: 13.79368\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1200 Loss: 11.37214\n",
      "Validation - Epoch: 1200 Loss: 13.04971\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1300 Loss: 10.95110\n",
      "Validation - Epoch: 1300 Loss: 12.28196\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1400 Loss: 10.59738\n",
      "Validation - Epoch: 1400 Loss: 11.66876\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1500 Loss: 10.30593\n",
      "Validation - Epoch: 1500 Loss: 11.16248\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1600 Loss: 9.58709\n",
      "Validation - Epoch: 1600 Loss: 11.02735\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1700 Loss: 9.56599\n",
      "Validation - Epoch: 1700 Loss: 11.26821\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1800 Loss: 9.57936\n",
      "Validation - Epoch: 1800 Loss: 11.66737\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1900 Loss: 9.48429\n",
      "Validation - Epoch: 1900 Loss: 11.50376\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2000 Loss: 9.31409\n",
      "Validation - Epoch: 2000 Loss: 10.93183\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2100 Loss: 9.20595\n",
      "Validation - Epoch: 2100 Loss: 10.65462\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2200 Loss: 9.12927\n",
      "Validation - Epoch: 2200 Loss: 10.47260\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2300 Loss: 9.07850\n",
      "Validation - Epoch: 2300 Loss: 10.46768\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2400 Loss: 9.54163\n",
      "Validation - Epoch: 2400 Loss: 14.09942\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2500 Loss: 8.95715\n",
      "Validation - Epoch: 2500 Loss: 10.24680\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2600 Loss: 8.97469\n",
      "Validation - Epoch: 2600 Loss: 10.49168\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2700 Loss: 8.67026\n",
      "Validation - Epoch: 2700 Loss: 9.36510\n",
      "Learning rate: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 15:11:34,794]\u001b[0m Trial 2 finished with value: 9.4520263671875 and parameters: {'learning_rate': 0.00048128931940501424, 'reg_param': 1.9578897201213005e-06}. Best is trial 2 with value: 9.4520263671875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 120.80882\n",
      "Validation - Epoch: 100 Loss: 135.64502\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 200 Loss: 61.14479\n",
      "Validation - Epoch: 200 Loss: 70.83080\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 300 Loss: 37.95190\n",
      "Validation - Epoch: 300 Loss: 44.72475\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 400 Loss: 29.02819\n",
      "Validation - Epoch: 400 Loss: 34.18402\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 500 Loss: 25.21510\n",
      "Validation - Epoch: 500 Loss: 30.01043\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 600 Loss: 22.92479\n",
      "Validation - Epoch: 600 Loss: 26.99216\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 700 Loss: 22.57653\n",
      "Validation - Epoch: 700 Loss: 27.84288\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 800 Loss: 19.62396\n",
      "Validation - Epoch: 800 Loss: 23.58224\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 900 Loss: 19.53071\n",
      "Validation - Epoch: 900 Loss: 24.08944\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1000 Loss: 18.72206\n",
      "Validation - Epoch: 1000 Loss: 22.28888\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1100 Loss: 17.57287\n",
      "Validation - Epoch: 1100 Loss: 21.63699\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1200 Loss: 22.50677\n",
      "Validation - Epoch: 1200 Loss: 26.69725\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1300 Loss: 16.52166\n",
      "Validation - Epoch: 1300 Loss: 21.06774\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1400 Loss: 14.89551\n",
      "Validation - Epoch: 1400 Loss: 18.15452\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1500 Loss: 15.93344\n",
      "Validation - Epoch: 1500 Loss: 19.95164\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1600 Loss: 14.10330\n",
      "Validation - Epoch: 1600 Loss: 18.59482\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1700 Loss: 13.84444\n",
      "Validation - Epoch: 1700 Loss: 18.19660\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1800 Loss: 13.85687\n",
      "Validation - Epoch: 1800 Loss: 17.94243\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 1900 Loss: 13.46929\n",
      "Validation - Epoch: 1900 Loss: 17.68056\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2000 Loss: 13.83741\n",
      "Validation - Epoch: 2000 Loss: 17.66260\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2100 Loss: 14.84902\n",
      "Validation - Epoch: 2100 Loss: 19.44483\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2200 Loss: 14.02677\n",
      "Validation - Epoch: 2200 Loss: 17.60648\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2300 Loss: 14.09227\n",
      "Validation - Epoch: 2300 Loss: 17.43926\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2400 Loss: 14.41658\n",
      "Validation - Epoch: 2400 Loss: 17.95291\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2500 Loss: 13.98367\n",
      "Validation - Epoch: 2500 Loss: 17.64583\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2600 Loss: 14.11864\n",
      "Validation - Epoch: 2600 Loss: 17.50721\n",
      "Learning rate: 0.0002\n",
      "Training - Epoch: 2700 Loss: 13.73768\n",
      "Validation - Epoch: 2700 Loss: 17.33261\n",
      "Learning rate: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 15:21:41,814]\u001b[0m Trial 3 finished with value: 17.329488255033556 and parameters: {'learning_rate': 0.0004938284901364233, 'reg_param': 6.0749960734256916e-06}. Best is trial 2 with value: 9.4520263671875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 55.92280\n",
      "Validation - Epoch: 100 Loss: 62.32881\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 200 Loss: 24.35702\n",
      "Validation - Epoch: 200 Loss: 26.36932\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 300 Loss: 16.07710\n",
      "Validation - Epoch: 300 Loss: 17.32844\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 400 Loss: 13.35591\n",
      "Validation - Epoch: 400 Loss: 14.77034\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 500 Loss: 11.84191\n",
      "Validation - Epoch: 500 Loss: 13.31574\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 600 Loss: 11.04359\n",
      "Validation - Epoch: 600 Loss: 12.43952\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 700 Loss: 10.55229\n",
      "Validation - Epoch: 700 Loss: 11.93004\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 800 Loss: 10.33653\n",
      "Validation - Epoch: 800 Loss: 11.67678\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 900 Loss: 9.92623\n",
      "Validation - Epoch: 900 Loss: 11.16912\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1000 Loss: 9.76842\n",
      "Validation - Epoch: 1000 Loss: 11.11604\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1100 Loss: 9.38828\n",
      "Validation - Epoch: 1100 Loss: 10.35469\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1200 Loss: 9.37664\n",
      "Validation - Epoch: 1200 Loss: 10.39043\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1300 Loss: 9.29848\n",
      "Validation - Epoch: 1300 Loss: 10.46441\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1400 Loss: 9.01708\n",
      "Validation - Epoch: 1400 Loss: 10.13868\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1500 Loss: 8.99102\n",
      "Validation - Epoch: 1500 Loss: 10.01208\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1600 Loss: 9.01277\n",
      "Validation - Epoch: 1600 Loss: 9.98590\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1700 Loss: 8.95256\n",
      "Validation - Epoch: 1700 Loss: 9.90340\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1800 Loss: 8.78972\n",
      "Validation - Epoch: 1800 Loss: 9.61565\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1900 Loss: 8.75779\n",
      "Validation - Epoch: 1900 Loss: 9.58513\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2000 Loss: 8.72899\n",
      "Validation - Epoch: 2000 Loss: 9.55793\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2100 Loss: 8.70279\n",
      "Validation - Epoch: 2100 Loss: 9.53309\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2200 Loss: 8.67809\n",
      "Validation - Epoch: 2200 Loss: 9.50290\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2300 Loss: 8.65185\n",
      "Validation - Epoch: 2300 Loss: 9.47870\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2400 Loss: 8.64966\n",
      "Validation - Epoch: 2400 Loss: 9.48599\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2500 Loss: 8.61987\n",
      "Validation - Epoch: 2500 Loss: 9.46481\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2600 Loss: 8.69758\n",
      "Validation - Epoch: 2600 Loss: 9.66611\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2700 Loss: 8.58213\n",
      "Validation - Epoch: 2700 Loss: 9.43813\n",
      "Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 15:31:36,639]\u001b[0m Trial 4 finished with value: 9.599572508127098 and parameters: {'learning_rate': 0.0009672964844509264, 'reg_param': 5.846326121643413e-07}. Best is trial 2 with value: 9.4520263671875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 58.58361\n",
      "Validation - Epoch: 100 Loss: 65.44868\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 200 Loss: 24.57439\n",
      "Validation - Epoch: 200 Loss: 29.25076\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 300 Loss: 16.72673\n",
      "Validation - Epoch: 300 Loss: 19.54906\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 400 Loss: 14.67145\n",
      "Validation - Epoch: 400 Loss: 18.56792\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 500 Loss: 13.12327\n",
      "Validation - Epoch: 500 Loss: 15.87778\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 600 Loss: 12.41183\n",
      "Validation - Epoch: 600 Loss: 14.84968\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 700 Loss: 11.87172\n",
      "Validation - Epoch: 700 Loss: 15.05519\n",
      "Learning rate: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 800 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 800 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:34:34,697]\u001b[0m Trial 5 pruned. Trial was pruned at 800 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 800 Loss: 11.32074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:34:56,175]\u001b[0m Trial 6 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 95.29287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:35:17,100]\u001b[0m Trial 7 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 212.78317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:35:38,447]\u001b[0m Trial 8 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 224.36421\n",
      "Training - Epoch: 100 Loss: 57.87640\n",
      "Validation - Epoch: 100 Loss: 66.58225\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 200 Loss: 24.73326\n",
      "Validation - Epoch: 200 Loss: 26.63037\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 300 Loss: 18.25756\n",
      "Validation - Epoch: 300 Loss: 20.44613\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 400 Loss: 15.23521\n",
      "Validation - Epoch: 400 Loss: 16.21095\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 500 Loss: 14.20793\n",
      "Validation - Epoch: 500 Loss: 14.37721\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 600 Loss: 13.61809\n",
      "Validation - Epoch: 600 Loss: 13.96134\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 700 Loss: 12.69569\n",
      "Validation - Epoch: 700 Loss: 13.03966\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 800 Loss: 12.98960\n",
      "Validation - Epoch: 800 Loss: 14.33256\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 900 Loss: 12.11078\n",
      "Validation - Epoch: 900 Loss: 12.28725\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 1000 Loss: 12.72974\n",
      "Validation - Epoch: 1000 Loss: 14.66070\n",
      "Learning rate: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 1100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 1100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:39:41,458]\u001b[0m Trial 9 pruned. Trial was pruned at 1100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1100 Loss: 12.68335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:40:03,106]\u001b[0m Trial 10 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 157.73830\n",
      "Training - Epoch: 100 Loss: 44.13828\n",
      "Validation - Epoch: 100 Loss: 47.00512\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 200 Loss: 20.73546\n",
      "Validation - Epoch: 200 Loss: 22.07223\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 300 Loss: 14.86509\n",
      "Validation - Epoch: 300 Loss: 17.07471\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 400 Loss: 12.83671\n",
      "Validation - Epoch: 400 Loss: 13.73500\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 500 Loss: 12.14197\n",
      "Validation - Epoch: 500 Loss: 13.41996\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 600 Loss: 12.36592\n",
      "Validation - Epoch: 600 Loss: 15.48739\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 700 Loss: 11.46619\n",
      "Validation - Epoch: 700 Loss: 12.84212\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 800 Loss: 11.54419\n",
      "Validation - Epoch: 800 Loss: 14.33410\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 900 Loss: 10.90669\n",
      "Validation - Epoch: 900 Loss: 11.86048\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1000 Loss: 10.83484\n",
      "Validation - Epoch: 1000 Loss: 11.83415\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1100 Loss: 11.19028\n",
      "Validation - Epoch: 1100 Loss: 13.13062\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1200 Loss: 11.10255\n",
      "Validation - Epoch: 1200 Loss: 12.66652\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1300 Loss: 11.05725\n",
      "Validation - Epoch: 1300 Loss: 12.54956\n",
      "Learning rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 1400 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 1400 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:45:14,028]\u001b[0m Trial 11 pruned. Trial was pruned at 1400 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1400 Loss: 10.72802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:45:36,413]\u001b[0m Trial 12 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 129.86015\n",
      "Training - Epoch: 100 Loss: 65.43329\n",
      "Validation - Epoch: 100 Loss: 78.45750\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 200 Loss: 29.50103\n",
      "Validation - Epoch: 200 Loss: 36.92634\n",
      "Learning rate: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 300 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 300 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:46:40,127]\u001b[0m Trial 13 pruned. Trial was pruned at 300 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 300 Loss: 20.73437\n",
      "Training - Epoch: 100 Loss: 46.85522\n",
      "Validation - Epoch: 100 Loss: 53.93203\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 200 Loss: 18.86287\n",
      "Validation - Epoch: 200 Loss: 22.82724\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 300 Loss: 13.10132\n",
      "Validation - Epoch: 300 Loss: 13.93379\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 400 Loss: 11.38486\n",
      "Validation - Epoch: 400 Loss: 11.82018\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 500 Loss: 11.08956\n",
      "Validation - Epoch: 500 Loss: 13.54308\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 600 Loss: 10.33710\n",
      "Validation - Epoch: 600 Loss: 10.94210\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 700 Loss: 10.47415\n",
      "Validation - Epoch: 700 Loss: 13.06982\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 800 Loss: 10.25349\n",
      "Validation - Epoch: 800 Loss: 12.71223\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 900 Loss: 9.89392\n",
      "Validation - Epoch: 900 Loss: 12.05366\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1000 Loss: 10.08238\n",
      "Validation - Epoch: 1000 Loss: 12.60816\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1100 Loss: 9.44129\n",
      "Validation - Epoch: 1100 Loss: 9.94159\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1200 Loss: 9.39533\n",
      "Validation - Epoch: 1200 Loss: 10.09605\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1300 Loss: 9.78271\n",
      "Validation - Epoch: 1300 Loss: 11.70223\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1400 Loss: 9.36645\n",
      "Validation - Epoch: 1400 Loss: 10.00110\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1500 Loss: 9.67123\n",
      "Validation - Epoch: 1500 Loss: 11.71006\n",
      "Learning rate: 0.0010\n",
      "Training - Epoch: 1600 Loss: 8.58176\n",
      "Validation - Epoch: 1600 Loss: 9.24918\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1700 Loss: 8.60198\n",
      "Validation - Epoch: 1700 Loss: 9.25179\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1800 Loss: 8.54251\n",
      "Validation - Epoch: 1800 Loss: 9.13548\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 1900 Loss: 8.49810\n",
      "Validation - Epoch: 1900 Loss: 9.02404\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2000 Loss: 8.43735\n",
      "Validation - Epoch: 2000 Loss: 8.89081\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2100 Loss: 8.40366\n",
      "Validation - Epoch: 2100 Loss: 8.88219\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2200 Loss: 8.38985\n",
      "Validation - Epoch: 2200 Loss: 8.86474\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2300 Loss: 8.35958\n",
      "Validation - Epoch: 2300 Loss: 8.81708\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2400 Loss: 8.32161\n",
      "Validation - Epoch: 2400 Loss: 8.76297\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2500 Loss: 8.30737\n",
      "Validation - Epoch: 2500 Loss: 8.76857\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2600 Loss: 8.29588\n",
      "Validation - Epoch: 2600 Loss: 8.77177\n",
      "Learning rate: 0.0005\n",
      "Training - Epoch: 2700 Loss: 8.26780\n",
      "Validation - Epoch: 2700 Loss: 8.71963\n",
      "Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 15:56:32,537]\u001b[0m Trial 14 finished with value: 8.84345588428062 and parameters: {'learning_rate': 0.0009948116958280154, 'reg_param': 1.484043353996687e-07}. Best is trial 14 with value: 8.84345588428062.\u001b[0m\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:56:53,502]\u001b[0m Trial 15 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 148.48690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 15:57:14,389]\u001b[0m Trial 16 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 98.62880\n",
      "Training - Epoch: 100 Loss: 62.47756\n",
      "Validation - Epoch: 100 Loss: 67.87203\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 200 Loss: 25.93712\n",
      "Validation - Epoch: 200 Loss: 28.06470\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 300 Loss: 17.36540\n",
      "Validation - Epoch: 300 Loss: 19.76620\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 400 Loss: 14.09731\n",
      "Validation - Epoch: 400 Loss: 15.00977\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 500 Loss: 12.60578\n",
      "Validation - Epoch: 500 Loss: 13.36336\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 600 Loss: 11.80476\n",
      "Validation - Epoch: 600 Loss: 12.40364\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 700 Loss: 11.19967\n",
      "Validation - Epoch: 700 Loss: 11.72668\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 800 Loss: 10.97576\n",
      "Validation - Epoch: 800 Loss: 11.90447\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 900 Loss: 10.61721\n",
      "Validation - Epoch: 900 Loss: 11.53687\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1000 Loss: 10.65401\n",
      "Validation - Epoch: 1000 Loss: 11.55143\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1100 Loss: 10.14068\n",
      "Validation - Epoch: 1100 Loss: 10.88048\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1200 Loss: 10.49853\n",
      "Validation - Epoch: 1200 Loss: 11.34899\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1300 Loss: 10.19000\n",
      "Validation - Epoch: 1300 Loss: 11.03647\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1400 Loss: 9.95813\n",
      "Validation - Epoch: 1400 Loss: 10.59662\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1500 Loss: 9.68396\n",
      "Validation - Epoch: 1500 Loss: 10.45122\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1600 Loss: 8.73710\n",
      "Validation - Epoch: 1600 Loss: 9.69399\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1700 Loss: 8.68452\n",
      "Validation - Epoch: 1700 Loss: 9.66960\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1800 Loss: 8.63985\n",
      "Validation - Epoch: 1800 Loss: 9.62083\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1900 Loss: 8.50210\n",
      "Validation - Epoch: 1900 Loss: 9.26264\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2000 Loss: 8.46772\n",
      "Validation - Epoch: 2000 Loss: 9.24015\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2100 Loss: 8.43203\n",
      "Validation - Epoch: 2100 Loss: 9.18189\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2200 Loss: 8.49101\n",
      "Validation - Epoch: 2200 Loss: 9.42669\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2300 Loss: 8.37487\n",
      "Validation - Epoch: 2300 Loss: 9.11625\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2400 Loss: 8.33380\n",
      "Validation - Epoch: 2400 Loss: 9.08114\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2500 Loss: 8.32157\n",
      "Validation - Epoch: 2500 Loss: 9.05671\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2600 Loss: 8.28554\n",
      "Validation - Epoch: 2600 Loss: 9.03040\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2700 Loss: 8.34428\n",
      "Validation - Epoch: 2700 Loss: 9.21020\n",
      "Learning rate: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 16:07:08,363]\u001b[0m Trial 17 finished with value: 9.001276413066275 and parameters: {'learning_rate': 0.0007316011382825938, 'reg_param': 2.0764624043112265e-06}. Best is trial 14 with value: 8.84345588428062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 49.90065\n",
      "Validation - Epoch: 100 Loss: 54.38967\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 200 Loss: 19.58533\n",
      "Validation - Epoch: 200 Loss: 21.16669\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 300 Loss: 14.67012\n",
      "Validation - Epoch: 300 Loss: 16.01367\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 400 Loss: 12.81774\n",
      "Validation - Epoch: 400 Loss: 16.30901\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 500 Loss: 11.64523\n",
      "Validation - Epoch: 500 Loss: 13.31364\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 600 Loss: 11.24889\n",
      "Validation - Epoch: 600 Loss: 14.22377\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 700 Loss: 10.61638\n",
      "Validation - Epoch: 700 Loss: 11.28780\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 800 Loss: 10.77211\n",
      "Validation - Epoch: 800 Loss: 11.84590\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 900 Loss: 11.16562\n",
      "Validation - Epoch: 900 Loss: 16.76831\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1000 Loss: 10.76198\n",
      "Validation - Epoch: 1000 Loss: 15.65612\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1100 Loss: 9.49201\n",
      "Validation - Epoch: 1100 Loss: 10.40626\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1200 Loss: 9.68804\n",
      "Validation - Epoch: 1200 Loss: 11.01657\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1300 Loss: 9.27116\n",
      "Validation - Epoch: 1300 Loss: 9.97207\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1400 Loss: 9.25970\n",
      "Validation - Epoch: 1400 Loss: 10.18062\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1500 Loss: 9.40455\n",
      "Validation - Epoch: 1500 Loss: 10.17955\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 1600 Loss: 8.76581\n",
      "Validation - Epoch: 1600 Loss: 9.23263\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1700 Loss: 8.72348\n",
      "Validation - Epoch: 1700 Loss: 9.20322\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1800 Loss: 8.80021\n",
      "Validation - Epoch: 1800 Loss: 9.55666\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 1900 Loss: 8.58244\n",
      "Validation - Epoch: 1900 Loss: 9.02215\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2000 Loss: 8.59304\n",
      "Validation - Epoch: 2000 Loss: 9.09601\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2100 Loss: 8.53662\n",
      "Validation - Epoch: 2100 Loss: 9.04698\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2200 Loss: 8.51047\n",
      "Validation - Epoch: 2200 Loss: 9.04115\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 2300 Loss: 8.48413\n",
      "Validation - Epoch: 2300 Loss: 9.06949\n",
      "Learning rate: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:15:51,897 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
      "/home/mpotto/.cache/pypoetry/virtualenvs/pyselect-ESLNoovx-py3.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 2400 is already reported.\n",
      "  warnings.warn(\n",
      "2022-02-23 16:15:51,934 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
      "\u001b[32m[I 2022-02-23 16:15:51,936]\u001b[0m Trial 18 finished with value: 9.145503716180789 and parameters: {'learning_rate': 0.000868644586089045, 'reg_param': 1.9733043274256124e-07}. Best is trial 14 with value: 8.84345588428062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 2400 Loss: 8.50281\n",
      "Validation - Epoch: 2400 Loss: 9.14550\n",
      "Learning rate: 0.0004\n",
      "Training - Epoch: 100 Loss: 53.72319\n",
      "Validation - Epoch: 100 Loss: 58.54495\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 200 Loss: 20.86315\n",
      "Validation - Epoch: 200 Loss: 21.92651\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 300 Loss: 14.72357\n",
      "Validation - Epoch: 300 Loss: 15.94150\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 400 Loss: 12.75892\n",
      "Validation - Epoch: 400 Loss: 13.75788\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 500 Loss: 11.97373\n",
      "Validation - Epoch: 500 Loss: 12.81752\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 600 Loss: 11.71337\n",
      "Validation - Epoch: 600 Loss: 12.59808\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 700 Loss: 11.22118\n",
      "Validation - Epoch: 700 Loss: 11.95482\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 800 Loss: 10.45281\n",
      "Validation - Epoch: 800 Loss: 11.19163\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 900 Loss: 10.52273\n",
      "Validation - Epoch: 900 Loss: 11.25831\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1000 Loss: 9.96505\n",
      "Validation - Epoch: 1000 Loss: 10.49242\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1100 Loss: 9.76147\n",
      "Validation - Epoch: 1100 Loss: 10.11436\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1200 Loss: 9.91198\n",
      "Validation - Epoch: 1200 Loss: 10.50897\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1300 Loss: 9.67204\n",
      "Validation - Epoch: 1300 Loss: 10.47267\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1400 Loss: 9.55978\n",
      "Validation - Epoch: 1400 Loss: 10.13738\n",
      "Learning rate: 0.0007\n",
      "Training - Epoch: 1500 Loss: 9.65337\n",
      "Validation - Epoch: 1500 Loss: 10.18122\n",
      "Learning rate: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 1600 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 1600 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:21:40,875]\u001b[0m Trial 19 pruned. Trial was pruned at 1600 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1600 Loss: 9.66903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:22:03,035]\u001b[0m Trial 20 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 61.76293\n",
      "Training - Epoch: 100 Loss: 57.74562\n",
      "Validation - Epoch: 100 Loss: 61.93685\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 200 Loss: 22.59647\n",
      "Validation - Epoch: 200 Loss: 23.55861\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 300 Loss: 14.91192\n",
      "Validation - Epoch: 300 Loss: 15.96601\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 400 Loss: 13.06300\n",
      "Validation - Epoch: 400 Loss: 14.21579\n",
      "Learning rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 500 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 500 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:23:52,478]\u001b[0m Trial 21 pruned. Trial was pruned at 500 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 500 Loss: 12.40991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:24:16,014]\u001b[0m Trial 22 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 73.60433\n",
      "Training - Epoch: 100 Loss: 51.04845\n",
      "Validation - Epoch: 100 Loss: 63.18789\n",
      "Learning rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 200 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 200 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:25:00,133]\u001b[0m Trial 23 pruned. Trial was pruned at 200 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 200 Loss: 24.48901\n",
      "Training - Epoch: 100 Loss: 49.77868\n",
      "Validation - Epoch: 100 Loss: 54.00511\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 200 Loss: 22.03570\n",
      "Validation - Epoch: 200 Loss: 23.74938\n",
      "Learning rate: 0.0009\n",
      "Training - Epoch: 300 Loss: 17.85148\n",
      "Validation - Epoch: 300 Loss: 19.89570\n",
      "Learning rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 400 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 400 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:26:26,352]\u001b[0m Trial 24 pruned. Trial was pruned at 400 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 400 Loss: 15.46322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:26:49,138]\u001b[0m Trial 25 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 67.33856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:27:11,629]\u001b[0m Trial 26 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 60.87590\n",
      "Training - Epoch: 100 Loss: 61.14218\n",
      "Validation - Epoch: 100 Loss: 66.40956\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 200 Loss: 26.96844\n",
      "Validation - Epoch: 200 Loss: 28.88577\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 300 Loss: 17.49859\n",
      "Validation - Epoch: 300 Loss: 19.44975\n",
      "Learning rate: 0.0008\n",
      "Training - Epoch: 400 Loss: 13.63942\n",
      "Validation - Epoch: 400 Loss: 15.10591\n",
      "Learning rate: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 500 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 500 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:29:00,354]\u001b[0m Trial 27 pruned. Trial was pruned at 500 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 500 Loss: 12.43481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:29:23,082]\u001b[0m Trial 28 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 68.31836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "Engine run is terminating due to exception: Trial was pruned at 100 epoch.\n",
      "\u001b[32m[I 2022-02-23 16:29:44,360]\u001b[0m Trial 29 pruned. Trial was pruned at 100 epoch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 100 Loss: 95.04212\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=30, callbacks=[best_model_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda2ca7-2dee-4668-b6f4-77ae24029216",
   "metadata": {},
   "source": [
    "Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18da69da-9e90-436c-9de6-ebb498c6e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9de85ae6-75ba-4e46-82cd-274743eb5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), '../models/comp-act.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a206620-9096-4cc0-9ca9-35d123770e34",
   "metadata": {},
   "source": [
    "Replicate best model on different test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9488a969-aac3-4578-a0f7-f5d8e0c8a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate(trial):\n",
    "    # Set replication seed\n",
    "    seed = trial.number + 1000\n",
    "    manual_seed(seed)\n",
    "    trial.set_user_attr('random_seed', value=seed)    \n",
    "    \n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test, batch_size=test_size)\n",
    "    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    trial.set_user_attr('device', value=device)\n",
    "    \n",
    "    reg_param = study.best_params['reg_param']\n",
    "    loss_fn = lambda y_pred, y_true: ridge_loss(y_pred, y_true, best_model, reg_param)\n",
    "    \n",
    "    best_model.to(device) \n",
    "        \n",
    "    # Add evaluators\n",
    "    test_metric = {'rmse': RootMeanSquaredError()}    \n",
    "    test_evaluator = create_supervised_evaluator(best_model, metrics=test_metric, device=device)\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_evaluator.run(test_loader)\n",
    "    test_rmse = test_evaluator.state.metrics['rmse']\n",
    "    \n",
    "    return test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "645737c1-98ec-48ec-a726-482fba6af635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 16:29:44,395]\u001b[0m A new study created in memory with name: no-name-df7c320b-62ab-4b95-9509-f16a4d6cc3a5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "replication = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "214e1a89-582f-4f46-bb6d-2f04856dd64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-23 16:29:44,406]\u001b[0m Trial 0 finished with value: 2.8540356569689176 and parameters: {}. Best is trial 0 with value: 2.8540356569689176.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "replication.optimize(replicate, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a6f524-44fb-44b7-b694-8b8fcbe1555c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1066e5d1-8ddd-4fac-bd32-6c389bd20668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1c3f5-b54b-47d7-9ff7-a3d791209cdb",
   "metadata": {},
   "source": [
    "### Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "322b38da-3f2a-48e1-b863-6c3430fbfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = best_model.rff_net[0].bandwidths.detach().to('cpu').numpy()\n",
    "indexes = np.arange(1, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a55328b-02f4-424d-8a03-2b45231323fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(indexes, np.abs(bands), width=0.9, alpha=0.8, color='teal')\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(axis=\"x\", style=\"plain\")\n",
    "ax.set_xlabel(\"Coefficient Index\")\n",
    "ax.set_ylabel(r\"$| 1/\\sigma |$\")\n",
    "plt.xticks(indexes, features[:-1], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d2b95-6e48-43e7-b161-0c884e236352",
   "metadata": {},
   "source": [
    "### Predictions on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "931e4f8a-7b0f-4105-9262-efcf3a1dcb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomFourierFeaturesNet(\n",
       "  (rff_net): Sequential(\n",
       "    (0): HadamardLayer(in_features=21)\n",
       "    (1): RandomFourierFeaturesLayer(in_features=21, out_features=600)\n",
       "    (2): Linear(in_features=600, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f5d53d-96db-4ceb-ada6-c136f5d914f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_y_test = y_test.squeeze().sort(dim=0)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "783e7aa2-a8fa-4d83-9714-86d953be40ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEMCAYAAAA8vjqRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAofElEQVR4nO3de5yUdfn/8dc1w6KA5AKiIoeVY4hIynfFfdhPU0Ih6ytiRpRmK7pYUV817Kupj9Sf6U9NPFFqogKmZWqSVhbgIZMKEVQERHCBOGscBCGOO3P9/pjZ9WZ3Z3dmd3bv2dn38/HYx87cM3PPdTsy134+1+dg7o6IiEgmImEHICIiLY+Sh4iIZEzJQ0REMqbkISIiGVPyEBGRjCl5iIhIxnIieZhZTzN71czeM7OlZnZF8nhnM5tjZh8kf3cKO1YREQHLhXkeZtYN6Obub5lZR2AhcB5QCmxz99vN7Fqgk7tfE16kIiICOdLycPdN7v5W8vZOYBnQHRgNzEg+bQaJhCIiIiHLiZZHkJkdC/wNGAysdffC5HEDPq68n8oRRxzhxx57bNMGKSKSRxYuXLjF3btm8po2TRVMQ5jZYcDvgCvd/ZNEvkhwdzezWjOdmU0AJgD06tWLBQsWNEe4IiJ5wczWZPqanOi2AjCzAhKJ40l3fy55+KNkPaSyLvLv2l7r7g+7e7G7F3ftmlHyFBGRBsiJ5JHsknoUWObudwceegH4dvL2t4Hnmzs2ERGpKVe6rT4PfAtYbGbvJI9dB9wOPG1mlwJrgLHhhCciIkE5kTzcfS5gKR7+YnPGIiIi9cuJbisREWlZlDxERCRjSh4iIpIxJQ8RkRZuyZIlNPeEbyUPEZEcsnb7WkZOG8mAyQMYOW0ka7evTfmc/pP7M+S2IQw9Yyi/+93vmjXOnFuepLGKi4tdM8xFpKUaOW0kq7atIu5xDMOp+zva3TGsarzq9075HpNOm5TRe5rZQncvzuQ1anmIiDRSOq2FdF9TmTiAehMHgJkdNNHhgTceaNhFZEjJQ0SkkcpmlrFq2ypiHmPVtlWUzSxr+GtaSGdQTkwSFBFpadZuX0vZzDJWb1tNzGNVx+MeZ9W2VYycNpLV21ZT2K6Qrbu3Vj1+/RnXM754PKu3ra5qYcQ9TvnWcgZMHkCceO1v6KSeSh0C1TxERBpg+CPDWbM99WK0EYtUJYfqohYlYhEOxA9kPa4IET64+oOMXtOQmodaHiIiDVBX4gBSJg6AmMcOaq1kVTO1TlTzEBHJoohFiFo0tPfu07lP87xXs7yLiEieKSosqvV41KJN16qoQ9Si9Onch6ljpjbL+6nbSkSkAW47+zZKny2tUbdoijpGOlZMWtGs76eWh4hIA9z48o2htDBqk6oV1JTU8hARqcO8tfOqWhgFkQK6dujKR7s+yonEEbUovTv3brauqiAlDxGROgS7pg7ED7Bx58aQI/pUc3dVBanbSkTyXjrLh8xbO4+Bdw+k7119GXj3QOatnQeEV8OoTxsL929/TRIUkbxXfUJfUWERr1z2ykHPGXj3wBqJIqyRU/UpiBQw/YLplPQqycr5NElQRKQW1Sf01TbBr7YWRq4ljtqSXliUPEQkLwXXnmrMc3JBmIXxVJQ8RCTnBb/kK79EexX2qvM1lavW1rZMSOXQ1tJnS+tdZiQXhFkYT0XJQ0RyXjARrNq2itJnSymIFtSZTIKr1gYVRAq47ezbgPrXp2ood0/ss5HHlDxEJOdVX758zfY1VavWrty6krMfO5u4xw9KJL0796615VERr6D02dI6Fy5srGwmju6f6Z61c2WThuqKSM7r3bk3EUt8XVX+Du62dyB+oMamSlPHTKVP5z41FikMPr8laBPJzb/xlTxEJOcFE0Gfzn0oKiyqSiJBcY/XWvwuiBQk9vlugdbvWB92CLXKzZQmIhLQq7AXsy6ZVXU/WECPWISKeAWOE7EIvTv3Bg6uk8Q9TptIG+Iez8kWh2FV8aW6nlyjloeItDiVyWTFpBXMHj+bvl361liSPFgncZy4x3Ny1FLUovTt0pfZ42fXeT25Ri0PEWnRqrdKKgUL5tn6Cz6bo6gqN26adcmsBg1FDptaHiKSl6rXSSr/gi+IFDT4nI1NHG0ibYiSKOBHLcrNX7wZ+LSLrXrRP5flfPIws1FmttzMys3s2rDjEZGWIdi1NXXMVMpmljFg8gC6dujaqARSn9oK+QArr17JsZ2OxS2xnmDMY9z48o1AzaHIuT7jHXI8eZhZFPgF8CVgEPANMxsUblQiErZUq+SmOn7hby+kfGs5MY+xcedGunboysqrVzZJbHXNH0mVJKoPRc7VInlQTicPYBhQ7u6r3H0/8BQwOuSYRCRkqbp5Sp8trUoS5VvLOfORM+l7V98ae3Bs3LmRAZMHNElsEYvUaNlULoeSKkmk6mLLZbmePLoD6wL31yePiUgrtmrrqoP+gl+1dRWQ2XIjTTFkt/LLf/oF0+nXpR9Ri9KvSz+mXzAdSJ0kgl1ssy6ZlfPFcsiT0VZmNgGYANCrV+7/RxeRxolGosTj8YPu54LgUODaRoClGhnWEuV6y2MD0DNwv0fy2EHc/WF3L3b34q5duzZbcCISjuqthsr7ld1DYWjKInwuyvXk8SbQ38x6m1lbYBzwQsgxiUjI+nTuU1U7MIyoRatqGEWFRTXWs2pqBZECunboWus2t+lsgdsS5XTycPcK4PvALGAZ8LS7Lw03KhFpDnV96d78xZurEkRwocN1O9ZREC2oeya5Jyb7ZcvKq1dS1KmID3d9WOs8jZY4hyMdOZ08ANz9RXcf4O593f3WsOMRkeZR15fujS/fWGvBO1g8T8myt2T69WdcD9Q9T6MlzuFIR84nDxFpnap/6ZZvLa9qhaTaIRAgTrzJhuEGRSzCbxf/Fqh7nkZLnMORDiUPEclJwS/dSpWtkPo2cmqOlXODrYi65mm0xDkc6bBs9v3lguLiYl+wYEHYYYhIIwUXC2yuZdSjRBPdWhgVXlF1/JiOx/D65a8f1OoJLmzY0pnZQncvzuQ1anmISKM1xYii4MS5fl361dhJsCk4zopJK3AO/qP6o10fAfnbimiIvJgkKCLhCm68VFncbuxf5PPWzqP02VIOxA8QtehB9Y+mUjnZsMfhPQ6ard7j8B5Afk3yayy1PESk0ZpiRFFl4oDmqWE05/vkAyUPEWm0phhRVJk4mktlDQNg3fZ1Bz1W/b6o20pEsqByv4zgTnjVBQvgld1A63esP+h2RrvoOWCB340QtehBcefq2lm5RMlDRBotnVpAsC4SrCcEbwfrJcd0PKbGUuqVKkeJWmJoVKMYVmNGeqq1s+RT6rYSkWYRrIukEpwMuK9iX8rnGZa1WeJtIjX/hg6unRXszpJPKXmISLOobdJfKjGPsXXP1k8PePKnUnbyRtV7VachufVT8hARoOlXfw0uZlgQKeCYjsekv/qt0aiEYRgFkQKiFqUgUpDo7kKtisbQDHMRAWiS2dPBInnEIpmNoMpCITwoalFWTFpxUEzBAn31WCviFTieVzPJU2nIDHMVzEUESG+uRqov3lSCRfJMi86OY157Qfyow46i4yEdM1q6pL6JfqlizaeVcLNJ3VYiAqQ3VyPTvSnSKZIfJNARYpZ6JFXUolVLlzRGsKuufGt5rbHm00q42aTkISJAekXiTGeSp10k98pf6XWjB4fwprv967odNSf6BZNhULBGooJ57dRtJSJAenM1enfufVBdpL6/yIOTB+useSRbGJkMvx05bSSrt63mqMOOYvN/NtdbT6mtOF9byyg4YTCtyYqtlFoeIpK24IipqEW5+Ys31/n84Mq42VzQMEq0qsXw4a4PKepUxMqrV9b5mli8Zm2kelddvy79WDFpBbMumaXEUQ8lDxGpU7AuUPpsKRXxxD4XMY9x48s31vn84JDfTOZ51JsIiNXafVZUWFTr8yMWoU+XmkNyNZ+j4ZQ8RKROwbrAgfiBqrpEqppHqqL6lUOvxGOeWFokCzMEaivuT79gOv269CNqUYoKiygqLKozMQRbRmptZEbzPESkTgMmD6h1OKxhtIm0Ie7xg2oE1Z8ftSjXdrqW/7v8/xLpEsEi9dc1ohatcwhuQaSAok5FaQ8ZlrppnoeIZF2wSB5MGMGJdMEFDatvpBSLx/jp1p8SPSKa9qS/+hLH9AumU9KrpLGXJo2g5CEiNVRfPr3n4T1rLJk+YPKAeruwgKo9wRujNczybmmUPESkhuBs63U71tGnc58aE/Kqt0giFknZxVVdQaSArh268tGuj9JatiSdkV3SvFQwF5Ea0pkMGBypFI1EORA/QMxjuDv11VJjHqN92/asmLQirfWuUo3skvCo5SEiNaSaDJhqbau+d/Wtem06E/0yXS9K60vlHrU8RAQ4eH7GgdgBeh7es8Yw10zXtkolmJCqz81oY21qXTpd60vlFiUPEQEOTgzrdqyjIFpQY/5D9e6s8s3lVFRU1Hq+6gkg1XpRwbkZ/br0Y86lc1gxaQWzx8+mb5e+msCXo9RtJSJAenWO4DBcd6dgdwEff/xxreera++MoFRraqWz1paER8lDJM+luwdHfYse7t+/n23btuHmmCX2EK84rIKSGTXnW1SudKsEkL9C77Yys5+Z2ftm9q6ZzTSzwsBjPzazcjNbbmYjQwxTpMVKVaeovgbVxFMm1rroYeXzBk8ZzE7bWW9BvHISn+S30JcnMbOzgVfcvcLM7gBw92vMbBDwG2AYcAzwEjDAve5B5FqeRORgtS0XsmLSihrbzlYuCRLchva3Y37LGQ+dwX/a/Ic49a+KW9+ChpKbGrI8SegtD3ef7e6VFbd5QI/k7dHAU+6+z91XA+UkEomIZCDVDoHVaxwH4gcOur9y60qOO+44PrFP0koc6W7KJPkh9ORRzXjgz8nb3YHg1l/rk8dEJCnV8udBqZYdr55UCiIFny6ZHod9H+6jW7du9OzYM62l1O8cdWf2LkxyXrMkDzN7ycyW1PIzOvCc64EK4MkGnH+CmS0wswWbN2/OZugiOS2deReplh2vnlSmXzCdPp37gMOBLQe45OhLmD9/Pr/65q+qnhccehsUsQi/eOMXTX69kjtCr3kAmFkpcDnwRXffnTz2YwB3/3/J+7OAm9z9n3WdSzUPaU1S1TMytXjxYgoLC+nZsydr1qwhHo/Tu3fNSXnBkVvV17Bq6HtL+FpkzcPMRgH/C5xbmTiSXgDGmdkhZtYb6A/MDyNGkVyVqp6Rrj179nD99dczdOhQrrrxKkZOG8lZz57Fd/76nVq7wIKtmH5d+jXqvaVlCz15AD8HOgJzzOwdM3sIwN2XAk8D7wF/ASbWN9JKpLVJVc9IpxbyyiuvMGTIEG677TYuvPBCtp+6PaOlR7SFa+uWE91W2aRuKxEOGoZb245/rz7/KqWlpfTp04df/vKXjBgxImtdYOlOSpTc0SK7rUTkU+m0GNIRHIbreNVy6eVbyyl9tpRzzz2Xm266icWLFzNixAig8V1glbK1eKLkNiUPkRyS6RdvqmTT4/AeKV+zZvsaOnXqxI033kj79u2rjjemCywonTWypOVT8hDJIZl+8aZKNgdi9W+wVF2qIb2ZJrRstWAktyl5iOSQTL94UyWbjTs3HvzEQGmz+v4Z9ck0oamQ3jpoVV2RHDJ1zNQaxea61LcSbhVLFMDTOWeD3yNJK+m2DkoeIjkk+MUbHLVUWcNYv2P9QSOYJp4ykatevApItApOa3cap59+Om3Oa0NFvPZNmjKVaUKT1kFDdUVyVHC4bVDlirezLpnFwLsHciCerG84xGNx2k5rS6wshlPz33bwtSKVNFRXJI8Eaw1BwbpDVeIAMIhEIyxatIi+XfrWupihRj9Jtih5iOSoYPE8yDAiFmHA5AE1X2Qw5BdDOBA7QM/De9ZYzFCjnyRblDxEclRw1FJRYRFFhUVELUqbSBsOxA7UWJiwUsxjrNuxjoJoASsmrWD2+Nn07dJXo58kq1TzEGlB3nzzTca9Oq7Gn32VuwBWP6ZVbiUdqnmI5KmdO3dy5ZVXUlJSQnxb/KBuqH5d+mmVW2l2Sh4iLcAtt9zCfffdx+WXX84fJ/6x1m4oTc6T5qRuK5Ec9eGHH7J9+3YGDhzIxx9/zLJlyzj11FPDDkvykLqtRPKAu/PII49w3HHHUVpairvTqVMnJQ7JKUoeIjlk+fLlnHnmmZSVlTFkyBBmzJiBWc09w0XClvbyJGb2DNABaAvEAHf3UU0VmEhrM3fuXEaMGEG7du2YOnUq48ePJxLR33eSm9L+P9PdvwYsAEYCo4A5TRWUSGuyc+dOAIYNG8YPfvADli1bxmWXXZZW4sjW5lEimcr0z5oBQA/gaKBP9sMRaT0++eQTJk6cyKBBg9ixYwdt27blZz/7GUcffXTa59CufRKWTFfVvRH4AYndAe7PfjgircPvf/97vv/977Np0yb+53/+h2g02qDzaNc+CUumLY9RwOHu/iNgbBPEI5LXdu/ezfnnn8+YMWPo0qUL8+bN45577uGwww5r0Pm0a5+EJdPk0RdYl7zdMcuxiOS9du3a4e7cfvvtLFiwgJNPPrlR59PEQAlLpt1WDrQzs8HAMU0Qj0jeWbp0KT/84Q95+OGHKSoq4rnnnsva8Fvt2idhybTlMRkw4FvAddkPRyR/7N27l5/85CecdNJJLFy4kA8++ABA8zYkL2Qyz8OA89z92iaMRyQvvPbaa1x++eUsX76ciy66iLvvvpuuXbuGHZZI1qSdPNzdzexkM/sGsCN57MUmi0ykBfv1r3/Nvn37+Mtf/sLIkSPDDkck6zJaGNHMvg1Utrnj7v54k0TVCFoYUcLg7jz77LP07t2b4uJiPvnkE6LRKB06dAg7NJF6NcfCiEeQmGH+FeCoDF8rkpfWrl3Lueeey9ixY5kyZQoAn/nMZ5Q4JK9lmjwi7v4Nd78AJQ9p5WKxGPfffz/HH388r7zyCpMnT+bRRx8NOyyRZpHpUN3jzeybydd1M7NzVPeQ1mratGlcccUVjBo1igcffJBjjz027JBEmk2mLY9XgQISdY/ZJLqxssLMJpmZm9kRyftmZvebWbmZvWtmQ7P1XiINtWfPHhYvXgzAxRdfzMyZM3nxxReVOKTVqbflYWZzgKvdfZG7z2iKIMysJ3A2EFwS9EtA/+TPKcCDyd8ioXj55Ze5/PLL2bNnDytXruTQQw/lvPPOCzsskVCk0/K4BrjXzKaZWbcmiuMe4H9JzGCvNBp43BPmAYVN+P4iKW3dupXS0lJGjBiBmfGrX/2KQw89NOywREJVb8vD3d8CzjSzrwJ/MbPngDvdfU82AjCz0cAGd19UbeZtdz5dRwtgffLYpmy8r0g61qxZQ3FxMdu3b+e6667jhhtuoF27dmGHJRK6tArmydnly0l0Hf0UKDOzH7v7r9J8/Usk9gCp7noSy5ycnV64Kc8/AZgA0KtXr8acSgRI1DbatWtHr169uOSSS/jWt77FCSecEHZYIjmj3m4rM/s7sIFE11J3oBQ4AxhmZg+n8ybuPsLdB1f/AVYBvYFFZvYvEhtNvWVmRyffs2fgND2Sx2o7/8PuXuzuxVoCQhqjoqKCyZMnU1RUxL/+9S/MjDvvvFOJQ6SadFoeE4D3vOZU9B+Y2bLGvLm7LwaOrLyfTCDF7r7FzF4Avm9mT5EolO9wd3VZSZNZuHAhZWVlvP322/z3f/83BQUFYYckkrPqbXm4+9JaEkelL2c5nqAXSbRMyoGpwPea8L2kFXN3fvSjHzFs2DA2bdrEM888w/PPP0/37t3DDk0kZ2U6SfAg7r4qW4Ekz3ds4LYDE7N5fpHamBk7d+7ksssu44477qCwsDDskERyXqaTBEXywr///W8uuugi5s+fD8ADDzzAL3/5SyUOkTQpeUir4u5MmzaNgQMH8vTTT7No0SIAIhH9UxDJhP7FSKtRXl7OiBEjGD9+PIMGDeKdd96hrKws7LBEWqRG1TxEWpJnnnmGBQsW8NBDD1FWVqbWhkgjZLQZVEugzaAkaP78+ezYsYOzzjqLAwcOsGXLFrp10yo3IkHNsRmUSIuwc+dOrrjiCkpKSrjhhhtwdwoKCpQ4RLJEyUPyzh/+8AcGDRrElClTmDhxInPmzKHaumki0kiqeUhe+dvf/sa5557L4MGDeeaZZygpKQk7JJG8pJaHtHjxeJwlS5YAcNppp/HEE0+wcOFCJQ6RJqTkIS3a+++/zxlnnMEpp5zChg0bMDMuvPBC2rZtG3ZoInlNyUNapH379nHzzTfzuc99jiVLljBlyhSOOeaYsMMSaTVU85AWZ/fu3Zx88sm89957jBs3jnvvvZejjjoq7LBEWhUlD2kx9u/fT9u2bWnfvj1f+9rXGDZsGOecc07YYYm0Suq2khZh5syZ9O3bt2ohw5tuukmJQyRESh6S0zZs2MCYMWM4//zzOeKII1QIF8kRSh6Ssx555BGOO+44Zs2axZ133sn8+fM58cQTww5LRFDNQ3LY5s2bKSkp4cEHH6Rv375hhyMiAVoYUXLG3r17ufXWWxk6dChjxowhFosRiUS0tIhIE9PCiNJi/fWvf2XIkCH89Kc/5e9//zsA0WhUiUMkRyl5SKi2bdvGZZddxplnnkksFmPOnDncddddYYclIvVQ8pBQzZkzh+nTp3PNNdewePFiRowYEXZIIpIGFcyl2a1Zs4Z33nmH0aNHM3bsWIYOHUr//v3DDktEMqCWhzSbWCzGvffey/HHH8+ECRPYs2cPZqbEIdICKXlIs3jnnXcoKSnhqquu4gtf+ALz58+nXbt2YYclIg2kbitpcuvWrWPYsGF06tSJp556irFjx2oUlUgLp5aHNJkPPvgAgJ49e/LYY4+xbNkyvv71rytxiOQBJQ/Jui1btnDxxRczcOBAKidsXnTRRXTu3DnkyEQkW9RtJVnj7jz55JNcddVVbN++neuuu47BgweHHZaINAElD8kKd+e8887jhRdeoKSkhKlTpypxiOQxJQ9plOD6U8OHD+fss8/mu9/9LpGIekRF8llO/As3sx+Y2ftmttTM7gwc/7GZlZvZcjMbGWaMUtOCBQsoLi7mueeeA+CKK65g4sSJShwirUDo/8rN7ExgNPA5dz8euCt5fBAwDjgeGAU8YGbR0AKVKrt27eKHP/whp5xyCh999JHma4i0QqEnD+C7wO3uvg/A3f+dPD4aeMrd97n7aqAcGBZSjJI0Z84cBg8ezD333MPll1/OsmXLtB2sSCuUCzWPAcBpZnYrsBe42t3fBLoD8wLPW588JiHasmUL7du3Z+7cuXz+858POxwRCUmzJA8zewk4upaHrk/G0BkoAU4GnjazPhmefwIwAaBXr16NC1YO4u5MmzaN/fv3853vfIdx48bx1a9+VXuJi7RyzdJt5e4j3H1wLT/Pk2hRPOcJ84E4cASwAegZOE2P5LHazv+wuxe7e3HXrl2b+nJajRUrVjB8+HAuvfRSnn/+edwdM1PiEJGcqHn8HjgTwMwGAG2BLcALwDgzO8TMegP9gflhBdma7N+/n1tvvZUhQ4bw9ttv8/DDD/OnP/1Jy4qISJVcqHk8BjxmZkuA/cC3PbGx+lIzexp4D6gAJrp7LMQ4W423336bG264ga997Wvcd999dOvWLeyQRCTHWOJ7On8UFxd75XpKkr6dO3cye/ZsvvrVrwKwePFiTjjhhJCjEpHmYGYL3b04k9fkQreVhOyFF15g0KBBjBs3jnXr1gEocYhInZQ8WrFNmzZxwQUXMHr0aDp16sTcuXPp2bNn/S8UkVYvF2oeEoK9e/cydOhQPv74Y2677TauvvpqCgoKwg5LRFoIJY9WZu3atfTs2ZNDDz2U++67j5NOOkl7iItIxtRt1Urs27ePm266iX79+lUtZDh27FglDhFpELU8WoHXX3+dCRMm8P7773PhhRdy2mmnhR2SiLRwannkueuvv57TTz+dvXv38uc//5knnniCI488MuywRKSFU/LIQ+5OPB4H4HOf+xyTJk1iyZIljBo1KuTIRCRfKHnkmXXr1nHeeedxzz33AIm6xl133UWHDh1CjkxE8omSR56IxWJMmTKFQYMG8dJLL3HIIYeEHZKI5DEVzPPA0qVLufTSS3njjTcYOXIkDz74IL179w47LBHJY0oeeWDHjh2sXr2aJ554gm9+85ta/VZEmpySB7B2+1rKZpaxettqenfuzdQxU+lVmNubSr366qvMnz+fa665hlNPPZV//etf2ktcRJqNah5A2cwyVm1bRcxjrNq2irKZZWGHlNK2bdsYP348w4cP59FHH2X37t0AShwi0qyUPIDV21YT98TQ1rjHWb1tdcgR1eTu/OY3v+G4447j8ccf59prr2XRokW0b98+7NBEpBVStxXQu3NvVm1bRdzjRCxC7865V2zeuHEj48eP54QTTmDOnDkMGTIk7JBEpBVTywOYOmYqfTr3IWpR+nTuw9QxU8MOCYCKigqee+453J3u3bszd+5c/vnPfypxiEjotJNgjnr77bcpKytj4cKFvPbaa5x++ulhhyQieUo7CeaB//znP/zoRz/i5JNPZv369Tz99NNayFBEco5qHjnE3TnrrLP45z//SVlZGXfccQedOnUKOywRkRqUPHLAli1bKCwspE2bNtxwww0cdthh6qYSkZymbqsQuTszZszgs5/9bNVChuecc44Sh4jkPCWPkJSXl3PWWWdRWlrKwIED+fKXvxx2SCIiaVPyCMGMGTM44YQTePPNN3nggQd4/fXXGTRoUNhhiYikTTWPZuTumBn9+/fnnHPO4f7776d79+5hhyUikjElj2awa9cubrjhBgDuvfdeTj31VE499dSQoxIRaTh1WzWxP/3pTxx//PHcf//9xGIx8m1Spoi0TkoeTeSjjz7i61//Ol/5ylfo2LEjc+fOZcqUKdprQ0TygpJHE9m1axezZ8/mlltu4a233lI3lYjkFdU8smj58uU8+eST3HzzzfTt25e1a9fSsWPHsMMSEcm60FseZnaimc0zs3fMbIGZDUseNzO738zKzexdMxsadqyp7N+/n1tuuYUhQ4YwZcoU1q5dC6DEISJ5K/TkAdwJ3OzuJwI/Sd4H+BLQP/kzAXiwqQJYu30tI6eNZMDkAYycNpK129em/dp//OMfnHTSSfzkJz9hzJgxLFu2jKKioqYKVUQkJ+RC8nDgM8nbhwMbk7dHA497wjyg0My6NUUADd2Gdt++fVxwwQXs2rWLP/7xjzz11FMcffTRTRGiiEhOyYWax5XALDO7i0Qyq6wsdwfWBZ63PnlsU7YDqNxFEBLb0K7atqrO58+aNYvhw4dzyCGH8Ic//IHPfvazHHbYYdkOS0QkZzVLy8PMXjKzJbX8jAa+C1zl7j2Bq4BHG3D+Ccl6yYLNmzdnHF/UonXer7RhwwbOP/98Ro0axfTp0wH4r//6LyUOEWl1mqXl4e4jUj1mZo8DVyTvPgM8kry9AegZeGqP5LHazv8w8DAkdhLMNL6KeEWd9+PxOA899BDXXnstBw4c4Pbbb6e0tDTTtxERyRu5UPPYCHwheXs48EHy9gvAxclRVyXADnfPepcVQJtImzrvl5WVMXHiRIYNG8aSJUu45pprKCgoaIpQRERahFyoeZQB95lZG2AviZFVAC8C5wDlwG7gkqYKIOaxGvf37t1LLBajQ4cOlJWVcfrpp3PxxRdrhriICDmQPNx9LvBftRx3YGJzxNCtYzc2fPJpj1ingk6ceOKJjBgxgp///OeUlJRQUlLSHKGIiLQIoSePXLDxk42f3nHYvHsztt8499xzwwtKRCSHKXkATqDGbhCJRnh38bt06NAhvKBERHJYLhTMc4+hxCEiUgclDxERyZiSRwoNWedKRKS1UPJIIeYxyreWU/psadihiIjkHCWPeqzZvibsEEREco6Sh4iIZEzJAziyw5EpHysq1N4cIiLVKXkAv/3Gb+nXpR9Ri1JUWERRYRFRi9KvSz+mXzA97PBERHKOJgkCvQp7MeuSWWGHISLSYqjlISIiGVPyEBGRjCl5iIhIxpQ8REQkY0oeIiKSMSUPERHJmCU27MsfZrYZaK41RY4AtjTTe+WK1njN0DqvuzVeM7TO6/6su3fM5AV5N8/D3bs213uZ2QJ3L26u98sFrfGaoXVed2u8Zmid121mCzJ9jbqtREQkY0oeIiKSMSWPxnk47ABC0BqvGVrndbfGa4bWed0ZX3PeFcxFRKTpqeUhIiIZU/JoADM70czmmdk7ZrbAzIYlj5uZ3W9m5Wb2rpkNDTvWbDKzH5jZ+2a21MzuDBz/cfKal5vZyDBjbCpmNsnM3MyOSN7P28/azH6W/JzfNbOZZlYYeCxvP2szG5W8rnIzuzbseJqKmfU0s1fN7L3kv+Urksc7m9kcM/sg+btTnSdyd/1k+APMBr6UvH0O8NfA7T8DBpQAb4Qdaxav+UzgJeCQ5P0jk78HAYuAQ4DewEogGna8Wb72nsAsEvOHjmgFn/XZQJvk7TuAO/L9swaiyevpA7RNXuegsONqomvtBgxN3u4IrEh+tncC1yaPX1v5uaf6UcujYRz4TPL24cDG5O3RwOOeMA8oNLNuYQTYBL4L3O7u+wDc/d/J46OBp9x9n7uvBsqBYSHF2FTuAf6XxOdeKW8/a3ef7e4VybvzgB7J2/n8WQ8Dyt19lbvvB54icb15x903uftbyds7gWVAdxLXOyP5tBnAeXWdR8mjYa4EfmZm64C7gB8nj3cH1gWetz55LB8MAE4zszfM7DUzOzl5PJ+vGTMbDWxw90XVHsrr6w4YT6KFBfl9zfl8bSmZ2bHAScAbwFHuvin50IfAUXW9Nu9mmGeLmb0EHF3LQ9cDXwSucvffmdlY4FFgRHPG1xTqueY2QGcSXTQnA0+bWZ9mDK/J1HPd15HoxskrdV2zuz+ffM71QAXwZHPGJs3DzA4Dfgdc6e6fmFnVY+7uZlbnUFwljxTcPWUyMLPHgSuSd58BHkne3kCif7xSj+SxFqGea/4u8JwnOkTnm1mcxBpALfqaIfV1m9kJJPr2FyX/YfUA3koOkGjR113XZw1gZqXAV4AvJj9zaOHXXI98vrYazKyAROJ40t2fSx7+yMy6ufumZBfsv1OfQd1WDbUR+ELy9nDgg+TtF4CLkyNxSoAdgWZgS/d7EkVzzGwAiaLiFhLXPM7MDjGz3kB/YH5YQWaTuy929yPd/Vh3P5ZEV8ZQd/+QPP6szWwUiRrPue6+O/BQ3n7WwJtAfzPrbWZtgXEkrjfvWOIvoUeBZe5+d+ChF4BvJ29/G3i+rvOo5dEwZcB9ZtYG2AtMSB5/kcQonHJgN3BJOOE1iceAx8xsCbAf+HbyL9KlZvY08B6JLo6J7h4LMc7mks+f9c9JjKiak2xxzXP377h73n7W7l5hZt8nMaouCjzm7ktDDqupfB74FrDYzN5JHrsOuJ1Ed/SlJEYWjq3rJJphLiIiGVO3lYiIZEzJQ0REMqbkISIiGVPyEBGRjCl5iIhIxpQ8REQkY0oeIiKSMSUPkUYys8Fm9o/A/aFm9nKYMYk0NU0SFGkkM4uQWLKmu7vHzOyvwA8rl70WyUdankSkkdw9bmZLgePNrD+wxt3fSi4uuMXd/wiJJOPu8TBjFckWJQ+R7JhHYs2g7wGjksf+D9A+uWdCCbDAzLaTTChm9pS7jzOzImASiV0JV7r7vc0dvEimVPMQyY55wE+Bme5euZT3XODXwC7gz3Ukhe8Be4CtwAlNHKdIVqjlIZId7wP7SOz5XSnYRbUj+Xsfn/6765D8HQF+5e7vNmmEIlmk5CGSHVcAP3b3/wSOLSKxG+E/SOx9AvAacGdyP4zC5LGfA7eZ2SZgp7vf3DwhizScRluJNIKZ9QX+BPzd3S8NOx6R5qLkISIiGVPBXEREMqbkISIiGVPyEBGRjCl5iIhIxpQ8REQkY0oeIiKSMSUPERHJmJKHiIhk7P8DU27zgmZH9KoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, best_model(X_test).detach().squeeze().numpy(), 'o', markersize=4, color='forestgreen')\n",
    "plt.plot(sorted_y_test, sorted_y_test, color='k', linestyle='dashed', zorder=-10)\n",
    "plt.xlabel(r\"$y_{\\mathrm{true}}$\")\n",
    "plt.ylabel(r\"$y_{\\mathrm{pred}}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3a033-9e11-4852-90c8-a7b8f97cb34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
